---
# =============================================================================
# Kubernetes Cluster Installation Playbook
# 
# Fixes applied:
# 1. Minimal working containerd configuration (SystemdCgroup = true)
# 2. Better Calico installation with proper wait logic
# 3. Increased timeouts and retries for reliability
# 
# Tested: January 7, 2026
# =============================================================================

- name: "Pre-flight Checks and System Preparation (All Nodes)"
  hosts: k8s_cluster
  become: yes
  tags:
    - preflight
    - all
  tasks:

    - name: Install required system packages for Kubernetes
      apt:
        name:
          - conntrack      # Required by kube-proxy
          - socat          # Required for kubectl port-forward
          - ebtables       # Required for iptables
          - ipset          # Required for kube-proxy
        state: present
        update_cache: yes

    - name: Disable swap immediately
      command: swapoff -a
      when: ansible_swaptotal_mb > 0
      changed_when: false

    - name: Disable swap permanently (remove from /etc/fstab)
      lineinfile:
        path: /etc/fstab
        regexp: '.*swap.*'
        state: absent

    - name: Verify swap is disabled
      shell: swapon --show
      register: swap_status
      changed_when: false
      failed_when: swap_status.stdout != ""

    - name: Load kernel modules for containerd
      modprobe:
        name: "{{ item }}"
        state: present
      loop: "{{ kernel_modules }}"

    - name: Ensure kernel modules load on boot
      copy:
        content: |
          # Kernel modules required for Kubernetes
          overlay
          br_netfilter
        dest: /etc/modules-load.d/k8s.conf
        mode: '0644'

    - name: Configure sysctl parameters for Kubernetes
      sysctl:
        name: "{{ item.key }}"
        value: "{{ item.value }}"
        state: present
        reload: yes
        sysctl_file: /etc/sysctl.d/k8s.conf
      loop: "{{ sysctl_config | dict2items }}"

    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600


# =============================================================================
- name: "Install and Configure containerd (All Nodes)"
  hosts: k8s_cluster
  become: yes
  tags:
    - containerd
    - all
  tasks:

    - name: Install containerd dependencies
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg
          - lsb-release
        state: present

    - name: Create keyrings directory for Docker GPG key
      file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'

    - name: Add Docker GPG key (containerd is from Docker repo)
      shell: |
        curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
        gpg --dearmor -o /etc/apt/keyrings/docker.gpg
      args:
        creates: /etc/apt/keyrings/docker.gpg

    - name: Add Docker repository (for containerd)
      apt_repository:
        repo: "deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
        state: present
        filename: docker

    - name: Install containerd
      apt:
        name: containerd.io
        state: present
        update_cache: yes

    # =========================================================================
    # CRITICAL FIX: Minimal working containerd configuration
    # This is the configuration proven to work during manual installation
    # =========================================================================
    - name: Create containerd config directory
      file:
        path: /etc/containerd
        state: directory
        mode: '0755'

    - name: Create minimal working containerd configuration
      copy:
        content: |
          version = 2
          
          [plugins]
            [plugins."io.containerd.grpc.v1.cri"]
              [plugins."io.containerd.grpc.v1.cri".containerd]
                [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
                  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                    runtime_type = "io.containerd.runc.v2"
                    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
                      SystemdCgroup = true
        dest: /etc/containerd/config.toml
        mode: '0644'
      notify: Restart containerd

    - name: Enable and start containerd service
      systemd:
        name: containerd
        enabled: yes
        state: started

    - name: Flush handlers to restart containerd now
      meta: flush_handlers

    - name: Wait for containerd to be ready
      wait_for:
        timeout: 10

    - name: Verify containerd is running
      command: systemctl is-active containerd
      register: containerd_status
      changed_when: false
      failed_when: containerd_status.stdout != "active"

  handlers:
    - name: Restart containerd
      systemd:
        name: containerd
        state: restarted


# =============================================================================
- name: "Install Kubernetes Components (All Nodes)"
  hosts: k8s_cluster
  become: yes
  tags:
    - kubernetes-packages
    - all
  tasks:

    - name: Install required packages for Kubernetes repository
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gpg
        state: present

    - name: Create keyrings directory
      file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'

    - name: Add Kubernetes GPG key
      shell: |
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v{{ kubernetes_version }}/deb/Release.key | \
        gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      args:
        creates: /etc/apt/keyrings/kubernetes-apt-keyring.gpg

    - name: Add Kubernetes repository
      apt_repository:
        repo: "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v{{ kubernetes_version }}/deb/ /"
        state: present
        filename: kubernetes

    - name: Install Kubernetes packages
      apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
        update_cache: yes

    - name: Hold Kubernetes packages (prevent automatic upgrades)
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - kubelet
        - kubeadm
        - kubectl

    - name: Enable kubelet service (will start after kubeadm init/join)
      systemd:
        name: kubelet
        enabled: yes


# =============================================================================
- name: "Initialize Kubernetes Control Plane"
  hosts: control_plane
  become: yes
  tags:
    - control-plane
    - all
  tasks:

    - name: Check if Kubernetes is already initialized
      stat:
        path: /etc/kubernetes/admin.conf
      register: kubeadm_init_stat

    - name: Initialize Kubernetes control plane with kubeadm
      command: >
        kubeadm init
        --pod-network-cidr={{ pod_network_cidr }}
        --service-cidr={{ service_cidr }}
        --apiserver-advertise-address={{ apiserver_advertise_address }}
        {{ kubeadm_init_extra_args }}
      register: kubeadm_init_output
      when: not kubeadm_init_stat.stat.exists

    - name: Display kubeadm init output (SAVE THE JOIN COMMAND!)
      debug:
        var: kubeadm_init_output.stdout_lines
      when: kubeadm_init_output is defined and kubeadm_init_output.stdout_lines is defined

    - name: Create .kube directory for non-root user
      file:
        path: "{{ kubernetes_user_home }}/.kube"
        state: directory
        owner: "{{ kubernetes_user }}"
        group: "{{ kubernetes_user }}"
        mode: '0755'

    - name: Copy admin.conf to user's kubeconfig
      copy:
        src: /etc/kubernetes/admin.conf
        dest: "{{ kubernetes_user_home }}/.kube/config"
        owner: "{{ kubernetes_user }}"
        group: "{{ kubernetes_user }}"
        mode: '0600'
        remote_src: yes

    - name: Generate kubeadm join command for workers
      command: kubeadm token create --print-join-command
      register: kubeadm_join_command
      changed_when: false

    - name: Save join command to local file
      local_action:
        module: copy
        content: "{{ kubeadm_join_command.stdout }}"
        dest: /tmp/kubeadm-join-command.sh
      become: no

    - name: Display join command
      debug:
        msg: "Worker nodes will use: {{ kubeadm_join_command.stdout }}"


# =============================================================================
- name: "Install Calico CNI Plugin"
  hosts: control_plane
  become: yes
  become_user: "{{ kubernetes_user }}"
  tags:
    - cni
    - all
  tasks:

    - name: Check if Calico is already installed
      command: kubectl get daemonset calico-node -n kube-system
      register: calico_check
      changed_when: false
      failed_when: false

    - name: Download Calico manifest
      get_url:
        url: "{{ calico_manifest_url }}"
        dest: /tmp/calico.yaml
        mode: '0644'
      when: calico_check.rc != 0

    - name: Configure Calico to use correct pod CIDR
      replace:
        path: /tmp/calico.yaml
        regexp: '192.168.0.0/16'
        replace: "{{ pod_network_cidr }}"
      when: calico_check.rc != 0

    - name: Apply Calico manifest
      command: kubectl apply -f /tmp/calico.yaml
      register: calico_apply
      when: calico_check.rc != 0

    - name: Display Calico apply output
      debug:
        var: calico_apply.stdout_lines
      when: calico_apply is defined and calico_apply.stdout_lines is defined

    # =========================================================================
    # FIX: Wait for DaemonSet to be created before waiting for pods
    # This prevents the "no resources found" error
    # =========================================================================
    - name: Wait for Calico DaemonSet to be created
      command: kubectl get daemonset calico-node -n kube-system
      register: calico_ds
      until: calico_ds.rc == 0
      retries: 12
      delay: 5
      when: calico_check.rc != 0

    - name: Display DaemonSet status
      debug:
        msg: "Calico DaemonSet created, waiting for pods to start..."
      when: calico_check.rc != 0

    # =========================================================================
    # FIX: Increased retries and delay for pod readiness
    # Some networks/systems take longer to pull images and start pods
    # =========================================================================
    - name: Wait for Calico pods to be ready (this may take 3-5 minutes)
      command: kubectl wait --for=condition=ready pod -l k8s-app=calico-node -n kube-system --timeout=180s
      register: calico_ready
      retries: 5
      delay: 20
      until: calico_ready.rc == 0
      when: calico_check.rc != 0

    - name: Verify Calico installation
      command: kubectl get pods -n kube-system -l k8s-app=calico-node
      register: calico_pods
      changed_when: false

    - name: Display Calico pods status
      debug:
        var: calico_pods.stdout_lines

    - name: Verify control plane node is Ready
      command: kubectl get nodes
      register: control_plane_node
      changed_when: false

    - name: Display control plane node status
      debug:
        var: control_plane_node.stdout_lines


# =============================================================================
- name: "Join Worker Nodes to Cluster"
  hosts: workers
  become: yes
  tags:
    - workers
    - all
  tasks:

    - name: Check if node is already part of cluster
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf_stat

    - name: Copy join command from control plane
      copy:
        src: /tmp/kubeadm-join-command.sh
        dest: /tmp/kubeadm-join-command.sh
        mode: '0700'
      when: not kubelet_conf_stat.stat.exists

    - name: Join worker node to cluster
      command: bash /tmp/kubeadm-join-command.sh
      register: kubeadm_join_output
      when: not kubelet_conf_stat.stat.exists

    - name: Display join output
      debug:
        var: kubeadm_join_output.stdout_lines
      when: kubeadm_join_output is defined and kubeadm_join_output.stdout_lines is defined

    - name: Verify kubelet is running
      systemd:
        name: kubelet
        state: started
        enabled: yes

    # Wait a bit for kubelet to register with API server
    - name: Wait for kubelet to register with cluster
      pause:
        seconds: 15
      when: not kubelet_conf_stat.stat.exists


# =============================================================================
- name: "Verify Cluster Installation"
  hosts: control_plane
  become: yes
  become_user: "{{ kubernetes_user }}"
  tags:
    - verify
    - all
  tasks:

    - name: Wait for all nodes to be Ready (may take 2-3 minutes)
      command: kubectl wait --for=condition=ready nodes --all --timeout=180s
      register: nodes_ready
      retries: 5
      delay: 15
      until: nodes_ready.rc == 0

    - name: Get cluster nodes
      command: kubectl get nodes -o wide
      register: cluster_nodes
      changed_when: false

    - name: Display cluster nodes
      debug:
        var: cluster_nodes.stdout_lines

    - name: Wait for all Calico pods to be running on all nodes
      command: kubectl wait --for=condition=ready pod -l k8s-app=calico-node -n kube-system --timeout=180s --all
      register: all_calico_ready
      retries: 3
      delay: 10
      until: all_calico_ready.rc == 0

    - name: Get all pods in kube-system namespace
      command: kubectl get pods -n kube-system -o wide
      register: system_pods
      changed_when: false

    - name: Display system pods
      debug:
        var: system_pods.stdout_lines

    - name: Get cluster info
      command: kubectl cluster-info
      register: cluster_info
      changed_when: false

    - name: Display cluster info
      debug:
        var: cluster_info.stdout_lines

    - name: Verify all system pods are running
      shell: kubectl get pods -n kube-system --field-selector=status.phase!=Running,status.phase!=Succeeded
      register: non_running_pods
      changed_when: false
      failed_when: non_running_pods.stdout != ""

    - name: Count total nodes
      shell: kubectl get nodes --no-headers | wc -l
      register: node_count
      changed_when: false

    - name: Count Ready nodes
      shell: kubectl get nodes --no-headers | grep -c " Ready"
      register: ready_node_count
      changed_when: false

    - name: Final health check summary
      debug:
        msg:
          - "=========================================="
          - "   Kubernetes Cluster Installation Complete!"
          - "=========================================="
          - ""
          - "Cluster endpoint: https://{{ apiserver_advertise_address }}:6443"
          - "Pod network CIDR: {{ pod_network_cidr }}"
          - "Service CIDR: {{ service_cidr }}"
          - "CNI plugin: {{ cni_plugin }} {{ calico_version }}"
          - "Kubernetes version: {{ kubernetes_version }}"
          - ""
          - "Nodes: {{ node_count.stdout }} total, {{ ready_node_count.stdout }} Ready"
          - ""
          - "To access cluster from your local machine:"
          - "  scp {{ kubernetes_user }}@{{ apiserver_advertise_address }}:~/.kube/config ~/.kube/config"
          - ""
          - "Next steps:"
          - "  1. kubectl get nodes -o wide"
          - "  2. kubectl get pods -A"
          - "  3. Deploy test application:"
          - "     kubectl create deployment nginx-test --image=nginx --replicas=3"
          - "     kubectl get pods -o wide"
          - ""
          - "=========================================="
